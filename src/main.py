from fastapi import FastAPI
from random import randint
import datetime
import redis as rds
import hashlib as hl
import Register
import uvicorn
from pydantic import BaseModel
from tango_kaiseki import split_noun
from tango_kaiseki import mrp_analisys
from tango_kaiseki import cleanning
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import UserRegister
import os

redis_endpoint = (os.getenv("REDISIPADDR"), int(os.getenv("REDISPORT")))
print(redis_endpoint)
IPADDR = (os.getenv("IPADDR"))
news1 = [
    {
        "Date": "2023/6/15",
        "Title": "ã€é‡è¦ã€‘æ–°æ›²ãƒªãƒªãƒ¼ã‚¹ï¼†ç”Ÿæ”¾é€æ±ºå®šï¼",
        "Description": "çš†æ§˜ã¸ã®æ„Ÿè¬ã®æ°—æŒã¡ã‚’è¾¼ã‚ã¦ã€æ–°æ›²ã®CDç™ºå£²ãŒæ±ºå®šã—ã¾ã—ãŸï¼ã•ã‚‰ã«ã€ãƒªãƒªãƒ¼ã‚¹è¨˜å¿µã¨ã—ã¦ç”Ÿæ”¾é€ã‚‚è¡Œã„ã¾ã™ã€‚ãŠæ¥½ã—ã¿ã«ï¼",
        "Url": IPADDR + "/news/news1"
    },
    {
        "Date": "2023/6/18",
        "Title": "ğŸµ ã‚µãƒãƒ¼ãƒ•ã‚§ã‚¹é–‹å‚¬æ±ºå®šï¼",
        "Description": "ç†±ã„å¤ã‚’ç››ã‚Šä¸Šã’ã‚‹ãŸã‚ã€ã‚µãƒãƒ¼ãƒ•ã‚§ã‚¹ã‚’é–‹å‚¬ã—ã¾ã™ï¼å¤šå½©ãªãƒãƒ³ãƒ‰ãŒå‡ºæ¼”äºˆå®šã§ã™ã€‚ãŠè¦‹é€ƒã—ãªãï¼",
        "Url": IPADDR + "/news/news2"
    },
    {
        "Date": "2023/6/22",
        "Title": "ã€ãƒ©ã‚¤ãƒ–æƒ…å ±ã€‘å…¨å›½ãƒ„ã‚¢ãƒ¼é–‹å‚¬ä¸­ï¼",
        "Description": "å…¨å›½å„åœ°ã‚’ã¾ã‚ã‚‹ãƒ„ã‚¢ãƒ¼ã‚’é–‹å‚¬ä¸­ã§ã™ï¼æ–°æ›²ã‚‚æŠ«éœ²ã—ã¾ã™ã®ã§ã€ãœã²ä¼šå ´ã«ãŠè¶Šã—ãã ã•ã„ï¼",
        "Url": IPADDR + "/news/news3"
    },
    {
        "Date": "2023/6/25",
        "Title": "ğŸ‰ ãƒ•ã‚¡ãƒ³æ„Ÿè¬ã‚¤ãƒ™ãƒ³ãƒˆé–‹å‚¬ã®ãŠçŸ¥ã‚‰ã›",
        "Description": "ãƒ•ã‚¡ãƒ³ã®çš†æ§˜ã¸ã®æ„Ÿè¬ã‚’è¾¼ã‚ãŸã‚¤ãƒ™ãƒ³ãƒˆã‚’é–‹å‚¬ã—ã¾ã™ï¼ç‰¹å…¸ã‚„ã‚µãƒ—ãƒ©ã‚¤ã‚ºãŒæº€è¼‰ã§ã™ã€‚ãŠæ¥½ã—ã¿ã«ï¼",
        "Url": IPADDR + "/news/news4"
    },
    {
        "Date": "2023/6/28",
        "Title": "ã€é‡è¦ã€‘ãƒ¡ãƒ³ãƒãƒ¼ã‚µãƒ—ãƒ©ã‚¤ã‚ºç”Ÿèª•ç¥­é–‹å‚¬ï¼",
        "Description": "ãƒ¡ãƒ³ãƒãƒ¼ã®èª•ç”Ÿæ—¥ã‚’ãŠç¥ã„ã™ã‚‹ã‚¹ãƒšã‚·ãƒ£ãƒ«ã‚¤ãƒ™ãƒ³ãƒˆã‚’è¡Œã„ã¾ã™ï¼ãŠèª•ç”Ÿæ—¥ã‚µãƒ—ãƒ©ã‚¤ã‚ºã‚‚è¦ãƒã‚§ãƒƒã‚¯ã§ã™ã€‚",
        "Url": IPADDR + "/news/news5"
    },
    {
        "Date": "2023/7/2",
        "Title": "ğŸ¶ æ–°ã‚¢ãƒ«ãƒãƒ åˆ¶ä½œé€²è¡Œä¸­ï¼",
        "Description": "æ–°ã—ã„ã‚¢ãƒ«ãƒãƒ ã®åˆ¶ä½œãŒé€²è¡Œä¸­ã§ã™ï¼æ–°ãŸãªéŸ³æ¥½ã§çš†æ§˜ã‚’é­…äº†ã—ã¾ã™ã€‚",
        "Url": IPADDR + "/news/news6"
    },
    {
        "Date": "2023/7/5",
        "Title": "ã€ãƒã‚±ãƒƒãƒˆç™ºå£²æƒ…å ±ã€‘æ¬¡å›ãƒ©ã‚¤ãƒ–é–‹å‚¬æ±ºå®šï¼",
        "Description": "æ¬¡å›ã®ãƒ©ã‚¤ãƒ–é–‹å‚¬ãŒæ±ºå®šã—ã¾ã—ãŸï¼ãƒã‚±ãƒƒãƒˆã®ç™ºå£²ã¯è¿‘æ—¥ä¸­ã«é–‹å§‹ã—ã¾ã™ã€‚",
        "Url": IPADDR + "/news/news7"
    },
    {
        "Date": "2023/7/9",
        "Title": "âœ¨ 10å‘¨å¹´è¨˜å¿µãƒ©ã‚¤ãƒ–é–‹å‚¬ï¼",
        "Description": "ãƒãƒ³ãƒ‰çµæˆ10å‘¨å¹´ã‚’è¨˜å¿µã—ã¦ã‚¹ãƒšã‚·ãƒ£ãƒ«ãƒ©ã‚¤ãƒ–ã‚’é–‹å‚¬ã—ã¾ã™ï¼ã“ã‚Œã¾ã§ã®æ„Ÿè¬ã‚’è¾¼ã‚ã¦ã€ç‰¹åˆ¥ãªæ¼”å‡ºã‚‚äºˆå®šã—ã¦ã„ã¾ã™ã€‚",
        "Url": IPADDR + "/news/news8"
    },
    {
        "Date": "2023/7/12",
        "Title": "ã€ãŠçŸ¥ã‚‰ã›ã€‘ãƒ¡ãƒ³ãƒãƒ¼ã‚°ãƒƒã‚ºæ–°ç™ºå£²ï¼",
        "Description": "æ–°ã—ã„ãƒ¡ãƒ³ãƒãƒ¼ã‚°ãƒƒã‚ºã®ç™ºå£²ãŒæ±ºå®šã—ã¾ã—ãŸï¼é™å®šã‚¢ã‚¤ãƒ†ãƒ ã‚‚ã‚ã‚Šã¾ã™ã®ã§ãŠè¦‹é€ƒã—ãªãã€‚",
        "Url": IPADDR + "/news/news9"
    },
    {
        "Date": "2023/7/15",
        "Title": "ğŸ¤ ã‚½ãƒ­ã‚³ãƒ³ã‚µãƒ¼ãƒˆé–‹å‚¬æ±ºå®šï¼",
        "Description": "ãƒ¡ãƒ³ãƒãƒ¼ã®ã‚½ãƒ­ã‚³ãƒ³ã‚µãƒ¼ãƒˆã‚’é–‹å‚¬ã—ã¾ã™ï¼ãã‚Œãã‚Œã®å€‹æ€§ãŒè¼ãã‚¹ãƒšã‚·ãƒ£ãƒ«ãªã‚¹ãƒ†ãƒ¼ã‚¸ã«ãªã‚‹ã“ã¨é–“é•ã„ãªã—ã€‚",
        "Url": IPADDR + "/news/news10"
    }
]
news2 = [
    {
        "Date":"2023/6/15", "Title":"ã€é‡è¦ã€‘æ–°æ›²ãƒªãƒªãƒ¼ã‚¹ï¼†ç”Ÿæ”¾é€æ±ºå®šï¼",
        "Description":"""çš†æ§˜ã¸ã®æ„Ÿè¬ã®æ°—æŒã¡ã‚’è¾¼ã‚ã¦ã€æ–°æ›²ã®CDç™ºå£²ãŒæ±ºå®šã—ã¾ã—ãŸï¼ã•ã‚‰ã«ã€ãƒªãƒªãƒ¼ã‚¹è¨˜å¿µã¨ã—ã¦ç”Ÿæ”¾é€ã‚‚è¡Œã„ã¾ã™ã€‚ãŠæ¥½ã—ã¿ã«ï¼""",
        "Url":IPADDR + "/news/news11"
    },
    {
        "Date":"2023/7/2", "Title":"ãƒ©ã‚¤ãƒ–ã‚¤ãƒ™ãƒ³ãƒˆé–‹å‚¬ã®ãŠçŸ¥ã‚‰ã›",
        "Description":"""ä»Šå¹´ã‚‚ã‚„ã£ã¦ãã¾ã—ãŸï¼ç§ãŸã¡ã®ãƒ©ã‚¤ãƒ–ã‚¤ãƒ™ãƒ³ãƒˆãŒ7æœˆ15æ—¥ã«é–‹å‚¬ã•ã‚Œã¾ã™ã€‚æ–°æ›²ã®æŠ«éœ²ã‚„ç‰¹åˆ¥ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ãŠè¦‹é€ƒã—ãªãï¼""",
        "Url":IPADDR + "/news/news12"},
    {
        "Date":"1994/8/10", "Title":"æ–°ã‚¢ãƒ«ãƒãƒ ã€å¤¢å¹»ã®æ—…ã€ç™ºå£²æ±ºå®šï¼",
        "Description":""""å¾…æœ›ã®æ–°ã‚¢ãƒ«ãƒãƒ ã€å¤¢å¹»ã®æ—…ã€ãŒ9æœˆ1æ—¥ã«ç™ºå£²ã•ã‚Œã¾ã™ã€‚å…¨æ›²ãƒ©ã‚¤ãƒ–ã§æŠ«éœ²ã™ã‚‹äºˆå®šã§ã™ã®ã§ã€ãœã²ãŠæ¥½ã—ã¿ã«ï¼""",
        "Url":IPADDR + "/news/news13"
    },
    {
        "Date":"2022/9/5", "Title":"ç”Ÿæ”¾é€ã®ãŠçŸ¥ã‚‰ã›ï¼",
        "Description":"""9æœˆ20æ—¥ã«ç‰¹åˆ¥ãªç”Ÿæ”¾é€ãŒã‚ã‚Šã¾ã™ã€‚æ–°æ›²ã®åˆæŠ«éœ²ã‚„ãƒ¡ãƒ³ãƒãƒ¼ã¨ã®ãƒˆãƒ¼ã‚¯ãŒç››ã‚Šã ãã•ã‚“ï¼ãŠè¦‹é€ƒã—ãªãï¼""",
        "Url":IPADDR + "/news/news14"
    },
    {
        "Date":"2022/10/1", "Title":"ãƒ©ã‚¤ãƒ–ãƒ„ã‚¢ãƒ¼é–‹å‚¬æ±ºå®šï¼",
        "Description":"""å…¨å›½ãƒ„ã‚¢ãƒ¼ã®é–‹å‚¬ãŒæ±ºå®šã—ã¾ã—ãŸï¼å„åœ°ã§ç†±ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ãŠå±Šã‘ã—ã¾ã™ã€‚æ—¥ç¨‹ã¨ãƒã‚±ãƒƒãƒˆæƒ…å ±ã¯å…¬å¼ã‚µã‚¤ãƒˆã‚’ã”ç¢ºèªãã ã•ã„ã€‚""",
        "Url":IPADDR + "/news/news15"
    },
    {
        "Date":"2022/10/20", "Title":"CDãƒªãƒªãƒ¼ã‚¹è¨˜å¿µã‚¤ãƒ™ãƒ³ãƒˆã®ãŠçŸ¥ã‚‰ã›",
        "Description":"""æ–°ã‚¢ãƒ«ãƒãƒ ã®ãƒªãƒªãƒ¼ã‚¹ã‚’è¨˜å¿µã—ã¦ã€11æœˆ5æ—¥ã«ã‚¤ãƒ™ãƒ³ãƒˆã‚’é–‹å‚¬ã—ã¾ã™ï¼ãƒ¡ãƒ³ãƒãƒ¼ã¨ã®æ¡æ‰‹ä¼šã‚„ç‰¹å…¸ä»˜ãã®CDè³¼å…¥ãŒå¯èƒ½ã§ã™ã€‚""",
        "Url":IPADDR + "/news/news16"
    },
    {
        "Date":"2022/11/15", "Title":"æ–°æ›²ã€Œå¤¢ã®ç¿¼ã€ã®CDç™ºå£²ãŒæ±ºå®šã—ã¾ã—ãŸï¼",
        "Description":"""å¾…æœ›ã®æ–°æ›²ã€Œå¤¢ã®ç¿¼ã€ã®CDãŒ12æœˆ1æ—¥ã«ç™ºå£²ã•ã‚Œã¾ã™ã€‚å¿ƒèºã‚‹ãƒ¡ãƒ­ãƒ‡ã‚£ã¨æ„Ÿå‹•ã®æ­Œè©ã‚’ãŠæ¥½ã—ã¿ãã ã•ã„ï¼""",
        "Url":IPADDR + "/news/news17"
    },
    {
        "Date":"2022/1/5", "Title":"ç”Ÿæ”¾é€ã‚¹ãƒšã‚·ãƒ£ãƒ«ã‚¤ãƒ™ãƒ³ãƒˆé–‹å‚¬æ±ºå®šï¼",
        "Description":"""æ–°å¹´ã‚’è¿ãˆã€1æœˆ20æ—¥ã«ç”Ÿæ”¾é€ã‚¹ãƒšã‚·ãƒ£ãƒ«ã‚¤ãƒ™ãƒ³ãƒˆã‚’è¡Œã„ã¾ã™ã€‚æ–°æ›²ã®ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚„ãƒ¡ãƒ³ãƒãƒ¼ã®ç”Ÿãƒˆãƒ¼ã‚¯ã‚’ãŠå±Šã‘ã—ã¾ã™ã€‚""",
        "Url":IPADDR + "/news/news18"
    },
    {
        "Date":"2023/2/10", "Title": "ãƒ©ã‚¤ãƒ–ãƒ„ã‚¢ãƒ¼è¿½åŠ å…¬æ¼”ã®ãŠçŸ¥ã‚‰ã›",
        "Description":"""å¤§å¥½è©•ã«ã¤ãã€ãƒ©ã‚¤ãƒ–ãƒ„ã‚¢ãƒ¼ã®è¿½åŠ å…¬æ¼”ãŒæ±ºå®šã—ã¾ã—ãŸï¼è¿½åŠ å…¬æ¼”ã®è©³ç´°ã‚„ãƒã‚±ãƒƒãƒˆã®è²©å£²æƒ…å ±ã¯å…¬å¼ã‚µã‚¤ãƒˆã§ã”ç¢ºèªãã ã•ã„ã€‚""",
        "Url":IPADDR + "/news/news19"
    },
    {
        "Date":"2023/3/15", "Title": "æ–°æ›²MVå…¬é–‹ï¼†CDç™ºå£²æƒ…å ±",
        "Description":"""æ–°æ›²ã€Œæœªæ¥ã¸ã®ä¸€æ­©ã€ã®MVãŒå®Œæˆã—ã¾ã—ãŸï¼ã•ã‚‰ã«ã€CDã®ç™ºå£²ã‚‚åŒæ™‚ã«æ±ºå®šã—ã¾ã—ãŸã®ã§ã€ãœã²ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚""",
        "Url":IPADDR + "/news/news20"
    }
]


app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class UserModel(BaseModel):
    UID:str

class RegisterModel(BaseModel):
    UID:str
    HASH:str


@app.post("/News")
def news(user:UserModel):

    my_rds = rds.Redis(host=redis_endpoint[0], port=redis_endpoint[1])

    #ãƒ©ãƒ³ãƒ€ãƒ ãªè¨˜äº‹ã‚’3ã¤é¸æŠã—ã¦ãã‚Œã‚’é–²è¦§ã—ãŸè¨˜äº‹ã¨ã™ã‚‹
    #é–²è¦§ã—ãŸè¨˜äº‹ã®åè©è¡¨ç¾ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–ã‚Šå‡ºã™(ãƒ¦ãƒ¼ã‚¶ã®å˜èªãƒªã‚¹ãƒˆã¨ã™ã‚‹)



    # random_number = [randint(0,len(news2)-1) for i in range(3)]
    # random_news_hash = [hl.md5((news2[i]['Description']+'-'+str(datetime.datetime.strptime(news2[i]['Date'],'%Y/%m/%d').timestamp())).encode()).hexdigest() for i in random_number]

    # random_title_noun = [(my_rds.hget(v,'Title').decode(), my_rds.hget(v,'Noun').decode()) for v in random_news_hash]
    # random_mrp = [v[1] for v in random_title_noun]
    # random_title = [v[0] for v in random_title_noun]
    # print(random_title)
    # mrp_serialize = ''
    # for word in random_mrp:
    #     mrp_serialize += word

    #redisã‹ã‚‰userã®å˜èªãƒªã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹
    # username = user.UID
    username = user.UID
    print(username)
    user_words = [word.decode() for word in my_rds.lrange(username, 0, -1)]

    mrp_serialize = ''
    for word in user_words:
        mrp_serialize += word
    
    #ã“ã“ã‹ã‚‰é¡ä¼¼åº¦ã‚’è¨ˆç®—ã™ã‚‹
    
    tfidf = TfidfVectorizer()

    
    #ãƒãƒƒã‚·ãƒ¥ã‚’ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã«ã—ãŸã‚‚ã®ã§æ—¥æ™‚ã§ã‚½ãƒ¼ãƒˆã™ã‚‹
    all_news_ranked = my_rds.zrevrange('NewsRank',0,11, withscores=True)
    all_description = [{'Title':my_rds.hget(v,'Title').decode(), 'Noun':my_rds.hget(v,'Noun').decode(), 'URL':my_rds.hget(v,'Url').decode(), 'Date':datetime.datetime.fromtimestamp(t).strftime("%Y-%m-%d"), 'Hash': v.decode()} for v,t in all_news_ranked]

    doc_dict_list = [{'Title':None, 'Noun':mrp_serialize, 'URL':None, 'Date':datetime.datetime.now(), 'Hash':None}] + all_description
    doc_list = [v['Noun'] for v in doc_dict_list]

    res_list = [{'Title':v['Title'], 'level':0, 'URL':v['URL'], 'Hash':v['Hash'], 'Date':v['Date'], 'ruijido':'0.0000'} for v in doc_dict_list[1:]]

    X = tfidf.fit_transform(doc_list)

    Xarray = X.toarray()

    ruijido = [v for v in cosine_similarity(Xarray)[0][1:]]
    if abs(max(ruijido) - min(ruijido)) <= 0:
        ruijido = [1 for v in ruijido]
    time_passed = [(datetime.datetime.now()-datetime.datetime.strptime(t['Date'],"%Y-%m-%d")).days for t in doc_dict_list[1:]]
    time_weighted = [v*time_weight(365,t) for v, t in zip(ruijido, time_passed)]

    print(time_weighted)

    max_ruijido = max(time_weighted)
    max_ruijido_quartor = max_ruijido/4

    for i, v in enumerate(time_weighted):
        level = 0
        if (max_ruijido_quartor*4) <= v:
            level = 1
        elif (max_ruijido_quartor*3) <= v < (max_ruijido_quartor*4):
            level = 2
        elif (max_ruijido_quartor*2) <= v < (max_ruijido_quartor*3):
            level = 3
        elif (max_ruijido_quartor) <= v < (max_ruijido_quartor*2):
            level = 4
        else:
            level = 5
        res_list[i]['Date'] = res_list[i]['Date']
        res_list[i]['level'] = level
        res_list[i]['ruijido'] = format(v, '.4f')
        print(level)
    
    return res_list

@app.get("/Noun")
async def get_noun(uid: str="yamasita"):
    my_rds = rds.Redis(host=redis_endpoint[0], port=redis_endpoint[1])
    user_words = [word.decode() for word in my_rds.lrange(uid, 0, -1)]
    return user_words

@app.post("/Register")
def register(data:RegisterModel):
    my_rds = rds.Redis(host=redis_endpoint[0], port=redis_endpoint[1])
    news_hash = data.HASH
    uid = data.UID

    worddata = my_rds.hget(news_hash,'Noun').decode()
    my_rds.rpush(uid,worddata)

    print([v.decode() for v in my_rds.lrange(uid,0,-1)])

    return data

def time_weight(max_day, x):
    if max_day <= x:
        return 0
    return (1/(x+1)) - (1/(max_day+1))
    
def main():
    print(redis_endpoint)
    my_rds = rds.Redis(host=redis_endpoint[0], port=redis_endpoint[1])
    # username = "test_user3"
    # user_words = [word.decode() for word in my_rds.lrange(username, 0, -1)]
    # print(user_words)
    # random_number = [randint(0,len(news2)-1) for i in range(3)]
    # random_news_hash = [hl.md5((news2[i]['Description']+'-'+str(datetime.datetime.strptime(news2[i]['Date'],'%Y/%m/%d').timestamp())).encode()).hexdigest() for i in [randint(0,len(news2)-1) for i in range(3)]]

    # random_title_noun = [(my_rds.hget(v,'Title').decode(), my_rds.hget(v,'Noun').decode()) for v in [hl.md5((news2[i]['Description']+'-'+str(datetime.datetime.strptime(news2[i]['Date'],'%Y/%m/%d').timestamp())).encode()).hexdigest() for i in [randint(0,len(news2)-1) for i in range(3)]]]
    # random_mrp = [v[1] for v in [(my_rds.hget(v,'Title').decode(), my_rds.hget(v,'Noun').decode()) for v in [hl.md5((news2[i]['Description']+'-'+str(datetime.datetime.strptime(news2[i]['Date'],'%Y/%m/%d').timestamp())).encode()).hexdigest() for i in [randint(0,len(news2)-1) for i in range(3)]]]]
    #random_mrpã®åè©ã‚’redisã«å…¥ã‚Œã‚‹
    
    # random_title = [v[0] for v in random_title_noun]
    # print(random_title)
    # mrp_serialize = ''
    # for word in random_mrp:
    #     mrp_serialize += word


    # DBåˆæœŸåŒ–ç”¨ã‚³ãƒ¼ãƒ‰
    # my_register1 = Register.Register(news1)
    # my_register1.register_noun()
    # my_register2 = Register.Register(news2)
    # my_register2.register_noun()
    # ur = UserRegister.UserRegister(["test_user_null"],[[v[1] for v in [(my_rds.hget(v,'Title').decode(), my_rds.hget(v,'Noun').decode()) for v in [hl.md5((news2[i]['Description']+'-'+str(datetime.datetime.strptime(news2[i]['Date'],'%Y/%m/%d').timestamp())).encode()).hexdigest() for i in [randint(0,len(news2)-1) for i in range(3)]]]] for i in range(3)])

    my_rds.flushdb()
    redis_initialize()
    ur = UserRegister.UserRegister(redis_endpoint[0],redis_endpoint[1],["yamasita", "tarou", "hanako"])
    ur.register_user()

    # my_rds = rds.Redis(host=redis_endpoint[0], port=redis_endpoint[1])
    # test = my_rds.zrevrange('NewsRank',0,-1,withscores=True)
    # print(test)
    # for v,t in test:
    #     print(datetime.datetime.fromtimestamp(t), my_rds.hget(v.decode(),'Title').decode())

    uvicorn.run(app, host="0.0.0.0", port=8000)

def redis_initialize():
    my_rds = rds.Redis(host=redis_endpoint[0], port=redis_endpoint[1])
    # DBåˆæœŸåŒ–ç”¨ã‚³ãƒ¼ãƒ‰
    my_register1 = Register.Register(news1, redis_endpoint[0],redis_endpoint[1])
    my_register1.register_noun()
    my_register2 = Register.Register(news2, redis_endpoint[0], redis_endpoint[1])
    my_register2.register_noun()
    ur = UserRegister.UserRegister(redis_endpoint[0],redis_endpoint[1],["test_user_null"],[[v[1] for v in [(my_rds.hget(v,'Title').decode(), my_rds.hget(v,'Noun').decode()) for v in [hl.md5((news2[i]['Description']+'-'+str(datetime.datetime.strptime(news2[i]['Date'],'%Y/%m/%d').timestamp())).encode()).hexdigest() for i in [randint(0,len(news2)-1) for i in range(3)]]]] for i in range(3)])

if __name__ == "__main__":
    main()
